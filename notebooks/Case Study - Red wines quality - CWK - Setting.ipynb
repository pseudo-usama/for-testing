{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3tKHubpeYWIO"
   },
   "source": [
    "#### This interactive Python notebook is about your assignment (course work) to do some data analysis about sampled data regarding the key elements and ingredients leading to high quality red wines. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "RV16YgSTX8MK"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Task 1: Import the data as of the Excel file \"winequality-red.cvs\". Subsequently, write the code that displays the number of rows and columns in your imported data sample. [1 Mark]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Task 2: Write the code and type in the answer to the question “which are the three top independent (feature) variables with the least spread of data values?”. [1 Mark]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Task 3: Write the code to generate and display the correlation matrix among all 12 variables (feature and target variables). Subsequently, answer the question about the top three feature variables, which appear to have the strongest correlation with the target variable “quality”. [3 Marks]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Task 4: Write the code to examine which variables do follow the normal (Gaussian) distribution. Subsequently, provide and justify your answer based on your observations. [3 Marks]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Task 5: Modify the given code such that a Principal Component Analysis (PCA) is carried out for all feature (independent) variables. Subsequently, draw a Scree plot to explain the ratio of variance as well as modify the given code to answer the question “which feature variables mostly contribute to the observed variance distribution by more than 30%”. [5 Marks]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "pca = PCA()\n",
    "# vals = X.values\n",
    "# pca.fit(vals)\n",
    "# wines_pca = pca.transform(vals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'PC 2')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "ax = plt.gca()\n",
    "# ax.scatter(wines_pca[:,0], wines_pca[:,1])\n",
    "ax.set_xlabel('PC 1')\n",
    "ax.set_ylabel('PC 2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Text(0, 0, 'PC0'), Text(1, 0, 'PC1')]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "ax = plt.gca()\n",
    "# expl_var = pca.explained_variance_ratio_\n",
    "# ax.plot(expl_var, marker='x')\n",
    "ax.set_ylim(0,1.)\n",
    "ax.set_xticks([0,1])\n",
    "ax.set_xticklabels([\"PC{}\".format(i) for i in range(2)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.axis.XTick at 0x24cbce6feb0>,\n",
       " <matplotlib.axis.XTick at 0x24cbce6fe80>]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# comps = pca.components_\n",
    "ax = plt.gca()\n",
    "# img = ax.imshow(comps, cmap='seismic', vmin=-1, vmax=1)\n",
    "# plt.colorbar(img, label=\"weight\")\n",
    "ax.set_yticks([0,1])\n",
    "t = ax.set_yticklabels([\"PC{}\".format(i+1) for i in range(2)])\n",
    "ax.set_xticks([0,1])\n",
    "# t = ax.set_xticklabels(X_feature_names, rotation=90)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(np.array(X_feature_names)[np.where(pca.components_[0,:] > 0.1)[0]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Task 6: Write/modify the code to repeat task 5, this time, however, this time with normalized values across all feature variables. Explain the observed differences and answer again the question: Which feature variables mostly contribute to the observed variance distribution by more than 30%? [5 Marks]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "hOTyT8ZhX8Mc"
   },
   "outputs": [],
   "source": [
    "# Normalize feature variables\n",
    "from sklearn import preprocessing as pp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "ss = pp.StandardScaler()\n",
    "# ss.fit(X.values)\n",
    "pca_norm = PCA()\n",
    "# pca_norm.fit(ss.transform(X.values))\n",
    "# wines_pca_norm = pca_norm.transform(ss.transform(X.values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(np.array(X_feature_names)[np.where(pca_norm.components_[0,:] > 0.3)[0]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Task 7: Write/modify the code to calculate the following two empirical probabilities (e.g., all 1599 rows as sample data): a) Probability of red wine quality to be less than 5, i.e., P(X<5), b) Probability of red wine quality to be equal or greater than 8, i.e., P(X ≥ 8), X = “quality”. [4 Marks]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot\n",
    "from numpy.random import normal\n",
    "from numpy import hstack\n",
    "from statsmodels.distributions.empirical_distribution import ECDF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Task 8: Let us assume that French wine makers and producers claim that it is possible to produce next year 1,000,000 bottles of red wines, to be considered as a population, a) with an average of quality equal or greater than 7, b) the distribution of quality scores will not be equal. Write the code, which states the Null (Ho) and alternative (H1) hypotheses such that you either reject or accept these two claims, (a) and (b), with confidence values 98% and 95%, respectively, on the basis of evidence provided by your 1599 large sample data. [6 Marks]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Task 9: Let us assume that you have a first attempt at estimating a simple linear regression model with all 11 predictor (feature) variables predicting the quality of red wine (target variable). The model should take the form: y = a + b1X1 + b2X2+….+b11X11, with a being the intercept and b1,…b11, the co-efficients. Assuming also that the values of the predictor variables are normalised, write the code, which will deliver an estimate of this model, i.e., intercept and coefficients, as well as an estimate of how fit is the model in terms of metrics such as R-square and the Mean Squared Error. [6 Marks]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize feature variables\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "# X_features = X\n",
    "# X_norm = StandardScaler().fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# Build linear regression model using different variables as predictors of quality\n",
    "# Split data into predictors X and output Y\n",
    "# predictors = ['fixed acidity', 'density', 'citric acid', 'chlorides', 'free sulfur dioxide', 'volatile acidity', 'pH', 'alcohol', 'sulphates', 'residual sugar', 'total sulfur dioxide']\n",
    "# X = df[predictors]\n",
    "# y = df['quality']\n",
    "\n",
    "# Initialise and fit model\n",
    "# lm = LinearRegression()\n",
    "# model = lm.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model evaluation\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "# mse=mean_squared_error(y,y_pred)\n",
    "  \n",
    "# rmse = np.sqrt(mean_squared_error(y, y_pred))\n",
    "# r2 = r2_score(y, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(f'alpha = {model.intercept_}')\n",
    "# print(f'betas = {model.coef_}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Task 10: Based on the result of task 9, you make now an attempt to improve your linear regression model by turning it into a polynomial expression, i.e., adding as parameters squared variables and/or their combinations. For instance, your model should take the form: y = a +b1X1 + b1X12 + b2X1X2 + ….+error. Write/modify the code such that different degrees up to 5 are tried out. In your attempts, you may opt for suppressing the Intercept. Subsequently, state your observations on how the performance of these models is improved in terms of the R-square metric. Finally, explain whether an improved performance, as measured by the R-square metric, can be trusted and suggest ways to prove this trust. [6 Marks]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "PoJqqC04X8Md"
   },
   "outputs": [],
   "source": [
    "# Splitting the data\n",
    "from sklearn.model_selection import train_test_split\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.25, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import PolynomialFeatures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_pol = PolynomialFeatures(degree=5, interaction_only=False, include_bias=False).fit_transform(X)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Copy of LIMEdemo.ipynb",
   "provenance": [
    {
     "file_id": "1vPtZflZswKfQTS_KMkx5MbO9HViLjyfF",
     "timestamp": 1620384176589
    }
   ]
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
